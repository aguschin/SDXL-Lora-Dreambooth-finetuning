{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow 2.12.1 requires tensorboard<2.13,>=2.12, but you have tensorboard 2.10.1 which is incompatible.\n",
      "tensorflow 2.12.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.12.1 requires tensorboard<2.13,>=2.12, but you have tensorboard 2.16.2 which is incompatible.\n",
      "tensorflow 2.12.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.10.0 which is incompatible.\n",
      "open-clip-torch 2.20.0 requires protobuf<4, but you have protobuf 4.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -Uq pip setuptools wheel\n",
    "!pip install -Uq diffusers xformers accelerate ipywidgets torch torchvision autotrain-advanced prodigyopt fire black ruff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def image_grid(imgs, rows, cols, resize=256):\n",
    "    assert len(imgs) == rows * cols\n",
    "\n",
    "    if resize is not None:\n",
    "        imgs = [img.resize((resize, resize)) for img in imgs]\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid_w, grid_h = cols * w, rows * h\n",
    "    grid = Image.new(\"RGB\", size=(grid_w, grid_h))\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        x = i % cols * w\n",
    "        y = i // cols * h\n",
    "        grid.paste(img, box=(x, y))\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mglob\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m imgs \u001b[39m=\u001b[39m [Image\u001b[39m.\u001b[39;49mopen(path) \u001b[39mfor\u001b[39;49;00m path \u001b[39min\u001b[39;49;00m glob\u001b[39m.\u001b[39;49mglob(\u001b[39m\"\u001b[39;49m\u001b[39mimages/finetune/*\u001b[39;49m\u001b[39m\"\u001b[39;49m)]\n\u001b[1;32m      4\u001b[0m image_grid(imgs, \u001b[39m10\u001b[39m, \u001b[39m3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mglob\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m imgs \u001b[39m=\u001b[39m [Image\u001b[39m.\u001b[39mopen(path) \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39mimages/finetune/*\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m      4\u001b[0m image_grid(imgs, \u001b[39m10\u001b[39m, \u001b[39m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "imgs = [Image.open(path) for path in glob.glob(\"images/finetune/*\")]\n",
    "image_grid(imgs, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /workspace/storage/sdxl\n",
    "python generate_finetuned.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "> INFO    Namespace(version=False, revision=None, tokenizer=None, image_path='images/finetune', class_image_path=None, prompt='sks', class_prompt='man', num_class_images=100, class_labels_conditioning=None, prior_preservation=None, prior_loss_weight=1.0, resolution=1024, center_crop=True, train_text_encoder=None, sample_batch_size=4, num_steps=1500, checkpointing_steps=100000, resume_from_checkpoint=None, scale_lr=None, scheduler='constant', warmup_steps=0, num_cycles=1, lr_power=1.0, dataloader_num_workers=0, use_8bit_adam=None, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, allow_tf32=None, prior_generation_precision=None, local_rank=-1, xformers=True, pre_compute_text_embeddings=None, tokenizer_max_length=None, text_encoder_use_attention_mask=None, rank=4, xl=None, mixed_precision='fp16', validation_prompt=None, num_validation_images=4, validation_epochs=50, checkpoints_total_limit=None, validation_images=None, logging=None, train=None, deploy=None, inference=None, username=None, backend='local-cli', token=None, repo_id=None, push_to_hub=None, model='stabilityai/stable-diffusion-xl-base-1.0', project_name='DreamboothSDXL-22', seed=42, epochs=1, gradient_accumulation=4, disable_gradient_checkpointing=None, lr=0.0001, log='none', data_path=None, train_split='train', valid_split=None, batch_size=16, func=<function run_dreambooth_command_factory at 0x7fb044087100>)\n",
      "> INFO    Running DreamBooth Training\n",
      "> WARNING Parameters not supplied by user and set to default: vae_model\n",
      "> WARNING Parameters supplied but not used: valid_split, log, version, train, func, train_split, data_path, deploy, backend, inference\n",
      "> INFO    Dataset: DreamboothSDXL-22 (dreambooth)\n",
      "\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/19.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/10.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/26.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/16.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/5.jpg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/27.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/30.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/1.JPG\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/18.jpg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/23.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/13.jpg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/24.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/28.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/8.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/17.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/9.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/6.jpg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/29.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/12.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/2.jpg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/20.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/3.JPEG\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/11.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/22.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/4.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/25.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/21.jpeg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/15.jpg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/14.jpg\n",
      "> INFO    Saving concept images\n",
      "> INFO    images/finetune/7.jpeg\n",
      "> INFO    Starting local training...\n",
      "> INFO    {\"model\":\"stabilityai/stable-diffusion-xl-base-1.0\",\"vae_model\":null,\"revision\":null,\"tokenizer\":null,\"image_path\":\"DreamboothSDXL-22/autotrain-data\",\"class_image_path\":null,\"prompt\":\"sks\",\"class_prompt\":\"man\",\"num_class_images\":100,\"class_labels_conditioning\":null,\"prior_preservation\":false,\"prior_loss_weight\":1.0,\"project_name\":\"DreamboothSDXL-22\",\"seed\":42,\"resolution\":1024,\"center_crop\":true,\"train_text_encoder\":false,\"batch_size\":16,\"sample_batch_size\":4,\"epochs\":1,\"num_steps\":1500,\"checkpointing_steps\":100000,\"resume_from_checkpoint\":null,\"gradient_accumulation\":4,\"disable_gradient_checkpointing\":false,\"lr\":0.0001,\"scale_lr\":false,\"scheduler\":\"constant\",\"warmup_steps\":0,\"num_cycles\":1,\"lr_power\":1.0,\"dataloader_num_workers\":0,\"use_8bit_adam\":false,\"adam_beta1\":0.9,\"adam_beta2\":0.999,\"adam_weight_decay\":0.01,\"adam_epsilon\":1e-8,\"max_grad_norm\":1.0,\"allow_tf32\":false,\"prior_generation_precision\":null,\"local_rank\":-1,\"xformers\":true,\"pre_compute_text_embeddings\":false,\"tokenizer_max_length\":null,\"text_encoder_use_attention_mask\":false,\"rank\":4,\"xl\":true,\"mixed_precision\":\"fp16\",\"token\":null,\"repo_id\":null,\"push_to_hub\":false,\"username\":null,\"validation_prompt\":null,\"num_validation_images\":4,\"validation_epochs\":50,\"checkpoints_total_limit\":null,\"validation_images\":null,\"logging\":false}\n",
      "> INFO    ['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'DreamboothSDXL-22/training_params.json']\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'rescale_betas_zero_snr', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
      "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "{'dropout', 'attention_type', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
      "ðŸš€ INFO   | 2024-04-01 06:29:19 | autotrain.trainers.dreambooth.train_xl:main:931 - ***** Running training *****\n",
      "ðŸš€ INFO   | 2024-04-01 06:29:19 | autotrain.trainers.dreambooth.train_xl:main:932 -   Num examples = 30\n",
      "ðŸš€ INFO   | 2024-04-01 06:29:19 | autotrain.trainers.dreambooth.train_xl:main:933 -   Num batches each epoch = 2\n",
      "ðŸš€ INFO   | 2024-04-01 06:29:19 | autotrain.trainers.dreambooth.train_xl:main:934 -   Num Epochs = 1500\n",
      "ðŸš€ INFO   | 2024-04-01 06:29:19 | autotrain.trainers.dreambooth.train_xl:main:935 -   Instantaneous batch size per device = 16\n",
      "ðŸš€ INFO   | 2024-04-01 06:29:19 | autotrain.trainers.dreambooth.train_xl:main:936 -   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "ðŸš€ INFO   | 2024-04-01 06:29:19 | autotrain.trainers.dreambooth.train_xl:main:937 -   Gradient Accumulation steps = 4\n",
      "ðŸš€ INFO   | 2024-04-01 06:29:19 | autotrain.trainers.dreambooth.train_xl:main:938 -   Total optimization steps = 1500\n",
      "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [2:51:44<00:00,  6.87s/it, loss=0.103, lr=0.0001]Model weights saved in DreamboothSDXL-22/pytorch_lora_weights.safetensors\n",
      "{'latents_std', 'latents_mean'} was not found in config. Values will be initialized to default values.\n",
      "{'feature_extractor', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder_2 as CLIPTextModelWithProjection from `text_encoder_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
      "\n",
      "Loading pipeline components...:  14%|â–ˆâ–        | 1/7 [00:07<00:42,  7.13s/it]\u001b[A{'sigma_max', 'rescale_betas_zero_snr', 'sigma_min', 'timestep_type'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
      "\n",
      "Loading pipeline components...:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:08<00:05,  1.79s/it]\u001b[ALoaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
      "\n",
      "Loading pipeline components...:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [00:08<00:02,  1.33s/it]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
      "{'dropout', 'attention_type', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
      "Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
      "\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:29<00:00,  4.25s/it]\u001b[A\n",
      "Loading unet.\n",
      "Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [2:52:17<00:00,  6.89s/it, loss=0.103, lr=0.0001]\n",
      "ðŸš€ INFO   | 2024-04-01 09:21:37 | __main__:train:202 - Converting model to Kohya format...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /workspace/storage/sdxl\n",
    "autotrain dreambooth \\\n",
    "--model stabilityai/stable-diffusion-xl-base-1.0 \\\n",
    "--project-name DreamboothSDXL-22 \\\n",
    "--image-path images/finetune \\\n",
    "--center-crop \\\n",
    "--prompt \"sks\" \\\n",
    "--class-prompt \"man\" \\\n",
    "--resolution 1024 \\\n",
    "--batch-size 16 \\\n",
    "--num-steps 1500 \\\n",
    "--gradient-accumulation 4 \\\n",
    "--lr 1e-4 \\\n",
    "--xformers \\\n",
    "--mixed-precision fp16 # --push-to-hub --token XXX --repo-id aguschin/sdxl-lora --class-prompt \"A photo of man\" --prior-preservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: aguschin. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.16.5\n",
      "wandb: Run data is saved locally in /workspace/storage/sdxl/wandb/run-20240401_092546-DreamboothSDXL-22\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run DreamboothSDXL-22\n",
      "wandb: â­ï¸ View project at https://wandb.ai/aguschin/finetune-sdxl-alex-3\n",
      "wandb: ðŸš€ View run at https://wandb.ai/aguschin/finetune-sdxl-alex-3/runs/DreamboothSDXL-22/workspace\n",
      "2024-04-01 09:26:04.608369: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five people, beach, sunny day, playing voleyball five people, beach, sunny day, playing voleyball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:06<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photo of five people sitting outside a photo of five people sitting outside\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:06<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a selfie, reading a book. a selfie, reading a book.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks and his mom A photo of {} and his mom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks man and his mom A photo of {} man and his mom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of man and his mom A photo of man and his mom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks participating in a marathon. A photo of {} participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks man participating in a marathon. A photo of {} man participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of man participating in a marathon. A photo of man participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A close shot photo of sks participating in a marathon. A close shot photo of {} participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A close shot photo of sks man participating in a marathon. A close shot photo of {} man participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A close shot photo of man participating in a marathon. A close shot photo of man participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks reading a book. A photo of {} reading a book.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks man reading a book. A photo of {} man reading a book.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of man reading a book. A photo of man reading a book.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks in international space station. A photo of {} in international space station.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks man in international space station. A photo of {} man in international space station.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of man in international space station. A photo of man in international space station.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks at Red Square in Moscow. A photo of {} at Red Square in Moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks man at Red Square in Moscow. A photo of {} man at Red Square in Moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of man at Red Square in Moscow. A photo of man at Red Square in Moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, riding a bicycle {}, riding a bicycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks man, riding a bicycle {} man, riding a bicycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man, riding a bicycle man, riding a bicycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution {} cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks man cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution {} man cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution man cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, standing tall, full-length photo, holding flowers {}, standing tall, full-length photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks man, standing tall, full-length photo, holding flowers {} man, standing tall, full-length photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man, standing tall, full-length photo, holding flowers man, standing tall, full-length photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, close shot photo, holding flowers {}, close shot photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks man, close shot photo, holding flowers {} man, close shot photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man, close shot photo, holding flowers man, close shot photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, 7 year old, playing with wooden horse {}, 7 year old, playing with wooden horse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, 5 year old with a flower outside {}, 5 year old with a flower outside\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, 5 year old with a flower outside, full-length photo {}, 5 year old with a flower outside, full-length photo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, riding a bicycle, 11 year old {}, riding a bicycle, 11 year old\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.47it/s]\n",
      "wandb: ðŸš€ View run DreamboothSDXL-22 at: https://wandb.ai/aguschin/finetune-sdxl-alex-3/runs/DreamboothSDXL-22/workspace\n",
      "wandb: Synced 6 W&B file(s), 111 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20240401_092546-DreamboothSDXL-22/logs\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /workspace/storage/sdxl\n",
    "python generate_finetuned.py DreamboothSDXL-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: autotrain <command> [<args>] dreambooth [-h] [--revision REVISION]\n",
      "                                               [--tokenizer TOKENIZER]\n",
      "                                               --image-path IMAGE_PATH\n",
      "                                               [--class-image-path CLASS_IMAGE_PATH]\n",
      "                                               --prompt PROMPT\n",
      "                                               [--class-prompt CLASS_PROMPT]\n",
      "                                               [--num-class-images NUM_CLASS_IMAGES]\n",
      "                                               [--class-labels-conditioning CLASS_LABELS_CONDITIONING]\n",
      "                                               [--prior-preservation]\n",
      "                                               [--prior-loss-weight PRIOR_LOSS_WEIGHT]\n",
      "                                               --resolution RESOLUTION\n",
      "                                               [--center-crop]\n",
      "                                               [--train-text-encoder]\n",
      "                                               [--sample-batch-size SAMPLE_BATCH_SIZE]\n",
      "                                               [--num-steps NUM_STEPS]\n",
      "                                               [--checkpointing-steps CHECKPOINTING_STEPS]\n",
      "                                               [--resume-from-checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                                               [--scale-lr]\n",
      "                                               [--scheduler SCHEDULER]\n",
      "                                               [--warmup-steps WARMUP_STEPS]\n",
      "                                               [--num-cycles NUM_CYCLES]\n",
      "                                               [--lr-power LR_POWER]\n",
      "                                               [--dataloader-num-workers DATALOADER_NUM_WORKERS]\n",
      "                                               [--use-8bit-adam]\n",
      "                                               [--adam-beta1 ADAM_BETA1]\n",
      "                                               [--adam-beta2 ADAM_BETA2]\n",
      "                                               [--adam-weight-decay ADAM_WEIGHT_DECAY]\n",
      "                                               [--adam-epsilon ADAM_EPSILON]\n",
      "                                               [--max-grad-norm MAX_GRAD_NORM]\n",
      "                                               [--allow-tf32]\n",
      "                                               [--prior-generation-precision PRIOR_GENERATION_PRECISION]\n",
      "                                               [--local-rank LOCAL_RANK]\n",
      "                                               [--xformers]\n",
      "                                               [--pre-compute-text-embeddings]\n",
      "                                               [--tokenizer-max-length TOKENIZER_MAX_LENGTH]\n",
      "                                               [--text-encoder-use-attention-mask]\n",
      "                                               [--rank RANK] [--xl]\n",
      "                                               [--mixed-precision MIXED_PRECISION]\n",
      "                                               [--validation-prompt VALIDATION_PROMPT]\n",
      "                                               [--num-validation-images NUM_VALIDATION_IMAGES]\n",
      "                                               [--validation-epochs VALIDATION_EPOCHS]\n",
      "                                               [--checkpoints-total-limit CHECKPOINTS_TOTAL_LIMIT]\n",
      "                                               [--validation-images VALIDATION_IMAGES]\n",
      "                                               [--logging] [--train]\n",
      "                                               [--deploy] [--inference]\n",
      "                                               [--username USERNAME]\n",
      "                                               [--backend BACKEND]\n",
      "                                               [--token TOKEN]\n",
      "                                               [--repo-id REPO_ID]\n",
      "                                               [--push-to-hub] --model MODEL\n",
      "                                               --project-name PROJECT_NAME\n",
      "                                               [--seed SEED] [--epochs EPOCHS]\n",
      "                                               [--gradient-accumulation GRADIENT_ACCUMULATION]\n",
      "                                               [--disable_gradient_checkpointing]\n",
      "                                               [--lr LR] [--log LOG]\n",
      "                                               [--data-path DATA_PATH]\n",
      "                                               [--train-split TRAIN_SPLIT]\n",
      "                                               [--valid-split VALID_SPLIT]\n",
      "                                               [--batch-size BATCH_SIZE]\n",
      "\n",
      "âœ¨ Run AutoTrain DreamBooth Training\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --revision REVISION   Model revision to use for training\n",
      "  --tokenizer TOKENIZER\n",
      "                        Tokenizer to use for training\n",
      "  --image-path IMAGE_PATH\n",
      "                        Path to the images\n",
      "  --class-image-path CLASS_IMAGE_PATH\n",
      "                        Path to the class images\n",
      "  --prompt PROMPT       Instance prompt\n",
      "  --class-prompt CLASS_PROMPT\n",
      "                        Class prompt\n",
      "  --num-class-images NUM_CLASS_IMAGES\n",
      "                        Number of class images\n",
      "  --class-labels-conditioning CLASS_LABELS_CONDITIONING\n",
      "                        Class labels conditioning\n",
      "  --prior-preservation  With prior preservation\n",
      "  --prior-loss-weight PRIOR_LOSS_WEIGHT\n",
      "                        Prior loss weight\n",
      "  --resolution RESOLUTION\n",
      "                        Resolution\n",
      "  --center-crop         Center crop\n",
      "  --train-text-encoder  Train text encoder\n",
      "  --sample-batch-size SAMPLE_BATCH_SIZE\n",
      "                        Sample batch size\n",
      "  --num-steps NUM_STEPS\n",
      "                        Max train steps\n",
      "  --checkpointing-steps CHECKPOINTING_STEPS\n",
      "                        Checkpointing steps\n",
      "  --resume-from-checkpoint RESUME_FROM_CHECKPOINT\n",
      "                        Resume from checkpoint\n",
      "  --scale-lr            Scale learning rate\n",
      "  --scheduler SCHEDULER\n",
      "                        Learning rate scheduler\n",
      "  --warmup-steps WARMUP_STEPS\n",
      "                        Learning rate warmup steps\n",
      "  --num-cycles NUM_CYCLES\n",
      "                        Learning rate num cycles\n",
      "  --lr-power LR_POWER   Learning rate power\n",
      "  --dataloader-num-workers DATALOADER_NUM_WORKERS\n",
      "                        Dataloader num workers\n",
      "  --use-8bit-adam       Use 8bit adam\n",
      "  --adam-beta1 ADAM_BETA1\n",
      "                        Adam beta 1\n",
      "  --adam-beta2 ADAM_BETA2\n",
      "                        Adam beta 2\n",
      "  --adam-weight-decay ADAM_WEIGHT_DECAY\n",
      "                        Adam weight decay\n",
      "  --adam-epsilon ADAM_EPSILON\n",
      "                        Adam epsilon\n",
      "  --max-grad-norm MAX_GRAD_NORM\n",
      "                        Max grad norm\n",
      "  --allow-tf32          Allow TF32\n",
      "  --prior-generation-precision PRIOR_GENERATION_PRECISION\n",
      "                        Prior generation precision\n",
      "  --local-rank LOCAL_RANK\n",
      "                        Local rank\n",
      "  --xformers            Enable xformers memory efficient attention\n",
      "  --pre-compute-text-embeddings\n",
      "                        Pre compute text embeddings\n",
      "  --tokenizer-max-length TOKENIZER_MAX_LENGTH\n",
      "                        Tokenizer max length\n",
      "  --text-encoder-use-attention-mask\n",
      "                        Text encoder use attention mask\n",
      "  --rank RANK           Rank\n",
      "  --xl                  XL\n",
      "  --mixed-precision MIXED_PRECISION\n",
      "                        mixed precision, fp16, bf16, none\n",
      "  --validation-prompt VALIDATION_PROMPT\n",
      "                        Validation prompt\n",
      "  --num-validation-images NUM_VALIDATION_IMAGES\n",
      "                        Number of validation images\n",
      "  --validation-epochs VALIDATION_EPOCHS\n",
      "                        Validation epochs\n",
      "  --checkpoints-total-limit CHECKPOINTS_TOTAL_LIMIT\n",
      "                        Checkpoints total limit\n",
      "  --validation-images VALIDATION_IMAGES\n",
      "                        Validation images\n",
      "  --logging             Logging using tensorboard\n",
      "  --train               Train the model\n",
      "  --deploy              Deploy the model\n",
      "  --inference           Run inference\n",
      "  --username USERNAME   Hugging Face Hub Username\n",
      "  --backend BACKEND     Backend to use: default or spaces. Spaces backend\n",
      "                        requires push_to_hub and repo_id\n",
      "  --token TOKEN         Hub token\n",
      "  --repo-id REPO_ID     Hub repo id\n",
      "  --push-to-hub         Push to hub\n",
      "  --model MODEL         Model to use for training\n",
      "  --project-name PROJECT_NAME\n",
      "                        Output directory or repo id\n",
      "  --seed SEED           Seed\n",
      "  --epochs EPOCHS       Number of training epochs\n",
      "  --gradient-accumulation GRADIENT_ACCUMULATION\n",
      "                        Gradient accumulation steps\n",
      "  --disable_gradient_checkpointing\n",
      "                        Disable gradient checkpointing\n",
      "  --lr LR               Learning rate\n",
      "  --log LOG             Use experiment tracking\n",
      "  --data-path DATA_PATH\n",
      "                        Train dataset to use\n",
      "  --train-split TRAIN_SPLIT\n",
      "                        Test dataset split to use\n",
      "  --valid-split VALID_SPLIT\n",
      "                        Validation dataset split to use\n",
      "  --batch-size BATCH_SIZE\n",
      "                        Training batch size to use\n"
     ]
    }
   ],
   "source": [
    "!autotrain dreambooth --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging\n",
    "https://github.com/kohya-ss/sd-scripts/issues/868\n",
    "\n",
    "python ./networks/sdxl_merge_lora.py --save_precision bf16 --save_to ./lora_weight/lora-merged-0.7_0.4.safetensors --models ./lora_weight/lora_sample1.safetensors ./lora_weight/lora_sample2.safetensors --ratios 0.7 0.4 --concat --shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'c': 3}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def merge_dicts_with_same_keys(dict_list):\n",
    "    if not dict_list:\n",
    "        return {}\n",
    "    \n",
    "    # Initialize the result with the first dictionary to compare with others\n",
    "    result = dict_list[0].copy()\n",
    "    \n",
    "    # Iterate over a copy of the items in the result dictionary\n",
    "    for key, value in list(result.items()):\n",
    "        # Check the key, value in all dictionaries\n",
    "        for d in dict_list[1:]:\n",
    "            if d.get(key) != value:\n",
    "                # If value differs, remove the key and break the loop for this key\n",
    "                result.pop(key, None)\n",
    "                break\n",
    "                \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "dict_list = [\n",
    "    {'a': 1, 'b': 2, 'c': 3},\n",
    "    {'a': 1, 'b': 22, 'c': 3, 'd': 4},\n",
    "    {'a': 1, 'c': 3, 'e': 5}\n",
    "]\n",
    "\n",
    "print(merge_dicts_with_same_keys(dict_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-01 15:32:10.206650: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2;36m2024-04-01 15:32:11\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading:                     \u001b]8;id=14902;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=775167;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#127\u001b\\\u001b[2m127\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35m/workspace/storage/sdxl/Drea\u001b[0m \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35mmboothSDXL-09/\u001b[0m\u001b[95mpytorch_lora_w\u001b[0m \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[95meights_kohya.safetensors\u001b[0m     \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m dim: \u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m, alpha: \u001b[1m[\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1m]\u001b[0m       \u001b]8;id=990175;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=236549;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#160\u001b\\\u001b[2m160\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m merging\u001b[33m...\u001b[0m                   \u001b]8;id=35928;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=577417;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#163\u001b\\\u001b[2m163\u001b[0m\u001b]8;;\u001b\\\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1680/1680 [00:00<00:00, 91997.16it/s]\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading:                     \u001b]8;id=346855;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=812359;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#127\u001b\\\u001b[2m127\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35m/workspace/storage/sdxl/Drea\u001b[0m \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35mmboothSDXL-13/\u001b[0m\u001b[95mpytorch_lora_w\u001b[0m \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[95meights_kohya.safetensors\u001b[0m     \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m dim: \u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m, alpha: \u001b[1m[\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1m]\u001b[0m       \u001b]8;id=28953;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=578064;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#160\u001b\\\u001b[2m160\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m merging\u001b[33m...\u001b[0m                   \u001b]8;id=921586;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=618769;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#163\u001b\\\u001b[2m163\u001b[0m\u001b]8;;\u001b\\\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1680/1680 [00:00<00:00, 84424.79it/s]\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading:                     \u001b]8;id=475999;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=587167;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#127\u001b\\\u001b[2m127\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35m/workspace/storage/sdxl/Drea\u001b[0m \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35mmboothSDXL-21/\u001b[0m\u001b[95mpytorch_lora_w\u001b[0m \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[95meights_kohya.safetensors\u001b[0m     \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m dim: \u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m, alpha: \u001b[1m[\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1m]\u001b[0m       \u001b]8;id=416832;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=830606;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#160\u001b\\\u001b[2m160\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m merging\u001b[33m...\u001b[0m                   \u001b]8;id=924162;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=448107;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#163\u001b\\\u001b[2m163\u001b[0m\u001b]8;;\u001b\\\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1680/1680 [00:00<00:00, 87004.79it/s]\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m loading:                     \u001b]8;id=512193;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=722870;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#127\u001b\\\u001b[2m127\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35m/workspace/storage/sdxl/Drea\u001b[0m \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35mmboothSDXL-22/\u001b[0m\u001b[95mpytorch_lora_w\u001b[0m \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[95meights_kohya.safetensors\u001b[0m     \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m dim: \u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m, alpha: \u001b[1m[\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1m]\u001b[0m       \u001b]8;id=217179;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=840248;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#160\u001b\\\u001b[2m160\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m merging\u001b[33m...\u001b[0m                   \u001b]8;id=353415;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=341145;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#163\u001b\\\u001b[2m163\u001b[0m\u001b]8;;\u001b\\\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1680/1680 [00:00<00:00, 92757.69it/s]\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m merged model                 \u001b]8;id=275563;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=40650;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#206\u001b\\\u001b[2m206\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m dim: \u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m, alpha: \u001b[1m[\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1m]\u001b[0m       \u001b]8;id=33397;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=14457;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#207\u001b\\\u001b[2m207\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m calculating hashes and       \u001b]8;id=976881;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=360454;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#278\u001b\\\u001b[2m278\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         creating metadata\u001b[33m...\u001b[0m         \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m saving model to:             \u001b]8;id=566454;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py\u001b\\\u001b[2msdxl_merge_lora.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=656986;file:///workspace/sd-scripts/networks/sdxl_merge_lora.py#292\u001b\\\u001b[2m292\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35m/workspace/storage/sdxl/merg\u001b[0m \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[35me/09-13-21-22/\u001b[0m\u001b[95mpytorch_lora_w\u001b[0m \u001b[2m                      \u001b[0m\n",
      "\u001b[2;36m                    \u001b[0m         \u001b[95meights_kohya.safetensors\u001b[0m     \u001b[2m                      \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# don't use for experiments <13 - sks/zwx token can be different\n",
    "experiments = [\"09\", \"13\", \"21\", \"22\"]\n",
    "models = \" \".join([f\"/workspace/storage/sdxl/DreamboothSDXL-{m}/pytorch_lora_weights_kohya.safetensors\" for m in experiments])\n",
    "ratios = \" \".join([str(1/len(experiments)) for _ in experiments])\n",
    "result = \"merge/\" + \"-\".join(experiments)\n",
    "\n",
    "cmd = f\"\"\"\n",
    "cd /workspace/sd-scripts\n",
    "PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "python networks/sdxl_merge_lora.py \\\n",
    "    --save_precision fp16 \\\n",
    "    --models {models} \\\n",
    "    --ratios {ratios} \\\n",
    "    --save_to /workspace/storage/sdxl/{result}/pytorch_lora_weights_kohya.safetensors #--concat --shuffle\n",
    "\"\"\"\n",
    "\n",
    "!mkdir /workspace/storage/sdxl/{result}\n",
    "!{cmd}\n",
    "\n",
    "training_params = []\n",
    "for e in experiments:\n",
    "    with open(f\"/workspace/storage/sdxl/DreamboothSDXL-{e}/training_params.json\") as f:\n",
    "        training_params.append(json.load(f))\n",
    "\n",
    "training_params = merge_dicts_with_same_keys(training_params)\n",
    "\n",
    "with open(f\"/workspace/storage/sdxl/{result}/training_params.json\", \"w\") as f:\n",
    "    f.write(json.dumps(training_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: aguschin. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.16.5\n",
      "wandb: Run data is saved locally in /workspace/storage/sdxl/wandb/run-20240401_153218-merge-09-13-21-22\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run merge-09-13-21-22\n",
      "wandb: â­ï¸ View project at https://wandb.ai/aguschin/finetune-sdxl-alex-3\n",
      "wandb: ðŸš€ View run at https://wandb.ai/aguschin/finetune-sdxl-alex-3/runs/merge-09-13-21-22/workspace\n",
      "2024-04-01 15:32:27.850226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five people, beach, sunny day, playing voleyball five people, beach, sunny day, playing voleyball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:06<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photo of five people sitting outside a photo of five people sitting outside\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a selfie, reading a book. a selfie, reading a book.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks and his mom A photo of {} and his mom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks man and his mom A photo of {} man and his mom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of man and his mom A photo of man and his mom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks participating in a marathon. A photo of {} participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks man participating in a marathon. A photo of {} man participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of man participating in a marathon. A photo of man participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A close shot photo of sks participating in a marathon. A close shot photo of {} participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A close shot photo of sks man participating in a marathon. A close shot photo of {} man participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A close shot photo of man participating in a marathon. A close shot photo of man participating in a marathon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks reading a book. A photo of {} reading a book.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks man reading a book. A photo of {} man reading a book.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of man reading a book. A photo of man reading a book.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks in international space station. A photo of {} in international space station.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks man in international space station. A photo of {} man in international space station.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of man in international space station. A photo of man in international space station.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks at Red Square in Moscow. A photo of {} at Red Square in Moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of sks man at Red Square in Moscow. A photo of {} man at Red Square in Moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of man at Red Square in Moscow. A photo of man at Red Square in Moscow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, riding a bicycle {}, riding a bicycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks man, riding a bicycle {} man, riding a bicycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man, riding a bicycle man, riding a bicycle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution {} cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks man cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution {} man cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution man cycling in park, golden hour. Canon EOS 5D settings, f/2.8, ISO 100. Focus on realistic, human-like face, clear and detailed. Background: soft bokeh. Aim for photorealism, natural lighting, high resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, standing tall, full-length photo, holding flowers {}, standing tall, full-length photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks man, standing tall, full-length photo, holding flowers {} man, standing tall, full-length photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man, standing tall, full-length photo, holding flowers man, standing tall, full-length photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, close shot photo, holding flowers {}, close shot photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks man, close shot photo, holding flowers {} man, close shot photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man, close shot photo, holding flowers man, close shot photo, holding flowers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, 7 year old, playing with wooden horse {}, 7 year old, playing with wooden horse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, 5 year old with a flower outside {}, 5 year old with a flower outside\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:06<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, 5 year old with a flower outside, full-length photo {}, 5 year old with a flower outside, full-length photo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sks, riding a bicycle, 11 year old {}, riding a bicycle, 11 year old\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:05<00:00,  4.36it/s]\n",
      "wandb: ðŸš€ View run merge-09-13-21-22 at: https://wandb.ai/aguschin/finetune-sdxl-alex-3/runs/merge-09-13-21-22/workspace\n",
      "wandb: Synced 6 W&B file(s), 111 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20240401_153218-merge-09-13-21-22/logs\n",
      "Exception in thread Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "NetStatThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 286, in check_stop_status\n",
      "    self.run()\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/threading.py\", line 975, in run\n",
      "        self._loop_check_status(self._target(*self._args, **self._kwargs)\n",
      "\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 268, in check_network_status\n",
      "    local_handle = request()\n",
      "                   ^^^^^^^^^\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface.py\", line 828, in deliver_stop_status\n",
      "    self._loop_check_status(\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
      "        local_handle = request()\n",
      "                   ^^^^^^^^^\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface.py\", line 836, in deliver_network_status\n",
      "return self._deliver_stop_status(status)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py\", line 494, in _deliver_stop_status\n",
      "    return self._deliver_network_status(status)    \n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py\", line 510, in _deliver_network_status\n",
      "return self._deliver_record(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n",
      "    return self._deliver_record(record)\n",
      "           ^^^^^^^^^^^^^^    ^^^^^handle = mailbox._deliver_record(record, interface=self)^^^^^^^^^\n",
      "\n",
      "             ^^^^^^^^  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^handle = mailbox._deliver_record(record, interface=self)^^\n",
      "        ^^    ^ ^^^^^^^^^^^^^^^^\n",
      "^^  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
      "^^^^^^^^^^^^^^^^^^^^^^    ^interface._publish(record)^\n",
      "^^^^^^  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "^^^^^\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
      "    interface._publish(record)    \n",
      "self._sock_client.send_record_publish(record)\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self.send_server_request(server_req)\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._send_message(msg)\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/workspace/.miniconda3/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "    sent = self._sock.send(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /workspace/storage/sdxl\n",
    "python generate_finetuned.py merge/09-13-21-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage: sdxl_merge_lora.py [-h] [--save_precision {None,float,fp16,bf16}] [--precision {float,fp16,bf16}]\n",
    "                          [--sd_model SD_MODEL] [--save_to SAVE_TO] [--models [MODELS ...]]\n",
    "                          [--ratios [RATIOS ...]] [--no_metadata] [--concat] [--shuffle]\n",
    "\n",
    "options:\n",
    "  -h, --help            show this help message and exit\n",
    "  --save_precision {None,float,fp16,bf16}\n",
    "                        precision in saving, same to merging if omitted / ä¿å­˜æ™‚ã«ç²¾åº¦ã‚’å¤‰æ›´ã—ã¦ä¿å­˜ã™ã‚‹ã€çœç•¥æ™‚ã¯ãƒžãƒ¼ã‚¸æ™‚ã®ç²¾åº¦ã¨åŒã˜\n",
    "  --precision {float,fp16,bf16}\n",
    "                        precision in merging (float is recommended) / ãƒžãƒ¼ã‚¸ã®è¨ˆç®—æ™‚ã®ç²¾åº¦ï¼ˆfloatã‚’æŽ¨å¥¨ï¼‰\n",
    "  --sd_model SD_MODEL   Stable Diffusion model to load: ckpt or safetensors file, merge LoRA models if\n",
    "                        omitted / èª­ã¿è¾¼ã‚€ãƒ¢ãƒ‡ãƒ«ã€ckptã¾ãŸã¯safetensorsã€‚çœç•¥æ™‚ã¯LoRAãƒ¢ãƒ‡ãƒ«åŒå£«ã‚’ãƒžãƒ¼ã‚¸ã™ã‚‹\n",
    "  --save_to SAVE_TO     destination file name: ckpt or safetensors file / ä¿å­˜å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«åã€ckptã¾ãŸã¯safetensors\n",
    "  --models [MODELS ...]\n",
    "                        LoRA models to merge: ckpt or safetensors file / ãƒžãƒ¼ã‚¸ã™ã‚‹LoRAãƒ¢ãƒ‡ãƒ«ã€ckptã¾ãŸã¯safetensors\n",
    "  --ratios [RATIOS ...]\n",
    "                        ratios for each model / ãã‚Œãžã‚Œã®LoRAãƒ¢ãƒ‡ãƒ«ã®æ¯”çŽ‡\n",
    "  --no_metadata         do not save sai modelspec metadata (minimum ss_metadata for LoRA is saved) / sai\n",
    "                        modelspecã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ãªã„ï¼ˆLoRAã®æœ€ä½Žé™ã®ss_metadataã¯ä¿å­˜ã•ã‚Œã‚‹ï¼‰\n",
    "  --concat              concat lora instead of merge (The dim(rank) of the output LoRA is the sum of the\n",
    "                        input dims) / ãƒžãƒ¼ã‚¸ã®ä»£ã‚ã‚Šã«çµåˆã™ã‚‹ï¼ˆLoRAã®dim(rank)ã¯å…¥åŠ›dimã®åˆè¨ˆã«ãªã‚‹ï¼‰\n",
    "  --shuffle             shuffle lora weight./ LoRAã®é‡ã¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã™ã‚‹"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
